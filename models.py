# -*- coding: utf-8 -*-
"""
Created on Tue Mar 23 08:19:52 2021

@author: Omer Sella
"""

import numpy as np
import torch
import torch.nn as nn
from torch.distributions.categorical import Categorical

MODELS_BOOLEAN_TYPE = np.bool
MODELS_INTEGER_TYPE = np.int32


def explicitMLP(inputLength, outputLength, hiddenLayersLengths, intermediateActivation = nn.Identity(), outputActivation = nn.Identity()):
    lengths = [inputLength] + hiddenLayersLengths + [outputLength]
    layerList = []
    
    
    for l in range(len(lengths) - 1):
        if (l < (len(lengths) - 2)):
            activation = intermediateActivation
        else:
            activation = outputActivation
        layerList = layerList + [nn.Linear(lengths[l], lengths[l+1]), activation()]
    
    result = nn.Sequential(*layerList)
    return result
        
    
class MLPCategorical(nn.Module):
    
    def __init__(self, mlpInputLength, logitsLength, hiddenLayersLengths, intemediateActivation = nn.Identity(), outputActivation = nn.Identity()):
        super().__init__()
        self.logitsNetwork = explicitMLP(mlpInputLength, logitsLength, hiddenLayersLengths, intemediateActivation, outputActivation)
        
        
    def _generateDistribution(self, observation):
        """
        A function to create a parametrised distribution
        
        Parameters
        ----------
        observation : a valid input to the model defined by the explicitMLP of the class.
            This doesn't have to be THE observation from the environment, it's just a borrowed name.

        Returns
        -------
        result : A categorical distribution.
            A categorical distribution over k, where 0 <= k < len(logitsLength) parametrised logits that were generated by an MLP.

        """
        logitsValue = self.logitsNetwork(observation)
        result = Categorical(logits=logitsValue)
        return result
    
    def _logProbabilitiesFromDistribution(self, categoricalDistribution, action):
        result = categoricalDistribution.log_prob(action).sum(axis = -1)
        return result
        
        
        
    def forward(self, observation, action = None):
        """
        Produce a categorical distribution.
        If action is given then compute their log likelihood of under the distribution produced.
        Parameters
        ----------
        observation : TYPE
            DESCRIPTION.
        action : TYPE, optional
            DESCRIPTION. The default is None.

        Returns
        -------
        categoricalDistribution : a categorical distribution
        logLikelihood : log likelihood of action if given. None otherwise.

        """
        
        logLikelihood = None
        categoricalDistribution = self._generateDistribution(observation)
        if action is not None:
            #Omer Sella: TODO: I'm using log probabilities to make log likelihood - doesn't look good.
            logLikelihood = self._logProbabilitiesFromDistribution(categoricalDistribution, action)
        return categoricalDistribution, logLikelihood
    
class actorCritic(nn.module):
    def __init__(self, observationSpaceType, observationSpaceSize, actionSpaceType, actionSpaceSize, maximumNumberOfHotBits, hiddenLayerParameters, actorCriticDevice):
        self.observationSpaceType = observationSpaceType
        self.observationSpaceSize = observationSpaceSize
        self.actionSpaceType = actionSpaceType
        self.actionSpaceSize = actionSpaceSize
        self.device = actorCriticDevice
        self.maxNumberOfHotBits = maximumNumberOfHotBits
        self.rowCoordinateRange = 2
        self.columnCoordinateRange = 16
        self.circulantSize = 511
        self.defaultHiddenLayerSizes = [64,64]
        self.defaultActivation = nn.Identity()

        self.rowCoordinateModel = MLPCategorical(self.observationSpaceSize, self.rowCoordinateRange, self.defaultHiddenLayerSizes)

        self.columnCoordinateModel = MLPCategorical(self.observationSpaceSize + 1, self.columnCoordinateRange, self.defaultHiddenLayerSizes)
        
        self.numberOfHotBitsModel = MLPCategorical(self.observationSpaceSize + 2, self.maximumNumberOfHotBits, self.defaultHiddenLayerSizes)
        
        self.to(actorCriticDevice)
        
    def actorActionToEnvAction(self, actorAction):
        i, j, hotCoordinates = actorAction
        """
        The actor is expected to produce i, j, and up to k coordinates which will be hot.
        The environment is expecting i,j and a binary vector.
        """
        binaryVector = np.zeros(self.circulantSize, dtype = MODELS_BOOLEAN_TYPE)
        binaryVector[hotCoordinates] = 1
        environmentStyleAction = [i, j, binaryVector]
        return environmentStyleAction
    
    def step(self, observations):
        with torch.no_grad():
            iCategoricalDistribution = self.rowCoordinateModel(observations)
            i = iCategoricalDistribution.sample()
            # Omer Sella: now we need to append i to the observations
            jCategoricalDistribution = self.columnCoordinateModel(observations)
            j = jCategoricalDistribution.sample()
            # Omer Sella: now we need to append j to the observations
            kCategoricalDistribution = self.numberOfHotBitsModel(observations)
            k = kCategoricalDistribution.sample()
        return i, j, k, logpI, logpJ, logpK
